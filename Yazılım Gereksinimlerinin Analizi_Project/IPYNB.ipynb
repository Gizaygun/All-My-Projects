{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29bc9c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Veri Seti       Unnamed: 1  \\\n",
      "0                                      Gereksinimler  Gereksinim Tipi   \n",
      "1  Kullanıcıların profil bilgilerini güncelleyebi...      Fonksiyonel   \n",
      "2  Profil oluşturma sırasında, evcil hayvanın tem...      Fonksiyonel   \n",
      "3  Kullanıcılar, evcil hayvanlarının sağlık geçmi...      Fonksiyonel   \n",
      "4  Randevu talepleri, platform üzerinden veterine...      Fonksiyonel   \n",
      "\n",
      "  Unnamed: 2  \n",
      "0      Yazar  \n",
      "1    ChatGPT  \n",
      "2    ChatGPT  \n",
      "3    ChatGPT  \n",
      "4    ChatGPT  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41 entries, 0 to 40\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Veri Seti   41 non-null     object\n",
      " 1   Unnamed: 1  41 non-null     object\n",
      " 2   Unnamed: 2  41 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Veri setini yükleme\n",
    "data_path = r'C:\\Users\\Gizem\\Desktop\\Veri_Seti_ChatGPT_İnsan.xlsx'\n",
    "data = pd.read_excel(data_path)\n",
    "# Veri setinin ilk beş satırını göster\n",
    "print(data.head())\n",
    "# Veri setinin sütun başlıklarını ve veri türlerini göster\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58250564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Gereksinimler', 'Gereksinim Tipi', 'Yazar'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Veri setini yükleme\n",
    "data_path = r'C:\\Users\\Gizem\\Desktop\\Veri_Seti_ChatGPT_İnsan.xlsx'\n",
    "data = pd.read_excel(data_path)\n",
    "\n",
    "# Veri setinin sütun başlıklarını ve veri türlerini göster\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0950a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                        gereksinimler\n",
      "1    kullanıcıların profil bilgilerini güncelleyebi...\n",
      "2    profil oluşturma sırasında evcil hayvanın teme...\n",
      "3    kullanıcılar evcil hayvanlarının sağlık geçmiş...\n",
      "4    randevu talepleri platform üzerinden veteriner...\n",
      "Name: Processed_Text, dtype: object\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 16 18 19 20 21 22 23 25 26\n",
      " 27 28 30 31] TEST: [15 17 24 29]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 26\n",
      " 27 28 29 31] TEST: [ 8  9 25 30]\n",
      "TRAIN: [ 1  2  3  5  6  7  8  9 10 11 13 14 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31] TEST: [ 0  4 12]\n",
      "TRAIN: [ 0  1  2  3  4  6  7  8  9 10 11 12 14 15 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31] TEST: [ 5 13 16]\n",
      "TRAIN: [ 0  2  3  4  5  6  7  8  9 10 12 13 14 15 16 17 18 19 20 21 22 24 25 26\n",
      " 27 28 29 30 31] TEST: [ 1 11 23]\n",
      "TRAIN: [ 0  1  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
      " 27 28 29 30 31] TEST: [ 2  3 26]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 23 24 25\n",
      " 26 28 29 30 31] TEST: [21 22 27]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 19 21 22 23 24 25\n",
      " 26 27 28 29 30] TEST: [18 20 31]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  8  9 11 12 13 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 30 31] TEST: [ 7 10 14]\n",
      "TRAIN: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14 15 16 17 18 20 21 22 23 24 25\n",
      " 26 27 29 30 31] TEST: [ 6 19 28]\n",
      "Eğitim kümesi boyutu: 32, Test kümesi boyutu: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Gizem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Gizem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# NLTK kütüphanesinin durak kelimeler ve WordNet lemmatizer'ını indir\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Veri setini yükleme\n",
    "data_path = r'C:\\Users\\Gizem\\Desktop\\Veri_Seti_ChatGPT_İnsan.xlsx'\n",
    "data = pd.read_excel(data_path)\n",
    "\n",
    "# Durak kelimeler listesi\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Lemmatizer nesnesi\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Küçük harfe çevirme\n",
    "    text = text.lower()\n",
    "    # Noktalama işaretlerini ve sayıları kaldır\n",
    "    text = re.sub(r'[\\d\\W]+', ' ', text)\n",
    "    # Tokenize etme ve durak kelimeleri kaldırma\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Kelimeleri kökten ayırma\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # Temizlenmiş metni geri döndür\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Metin sütununu önişle\n",
    "data['Processed_Text'] = data['Veri Seti'].apply(preprocess_text)\n",
    "\n",
    "# İlk beş işlenmiş metni göster\n",
    "print(data['Processed_Text'].head())\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# Önişleme adımı (metin önişlemeyi önceki adımda belirtilen gibi varsayıyorum)\n",
    "data['Processed_Text'] = data['Veri Seti'].apply(preprocess_text) # Metin sütununun adını düzeltin\n",
    "\n",
    "# Hedef sütun (ikinci sütun varsayılarak)\n",
    "target = data.iloc[:, 1] # İkinci sütunu hedef olarak kullan\n",
    "\n",
    "# Bağımsız değişkenler (özellikler)\n",
    "features = data['Processed_Text']\n",
    "\n",
    "# Veri setini eğitim ve test kümelerine ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# 10-katlı çapraz doğrulama için KFold nesnesi oluşturma\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# KFold ile çapraz doğrulama indexlerini yazdırma\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "# Eğitim ve test kümelerinin boyutlarını yazdır\n",
    "print(f\"Eğitim kümesi boyutu: {X_train.shape[0]}, Test kümesi boyutu: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93a59bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Gereksinimler Gereksinim Tipi    Yazar\n",
      "0  Kullanıcıların profil bilgilerini güncelleyebi...     Fonksiyonel  ChatGPT\n",
      "1  Profil oluşturma sırasında, evcil hayvanın tem...     Fonksiyonel  ChatGPT\n",
      "2  Kullanıcılar, evcil hayvanlarının sağlık geçmi...     Fonksiyonel  ChatGPT\n",
      "3  Randevu talepleri, platform üzerinden veterine...     Fonksiyonel  ChatGPT\n",
      "4  Veri güvenliği önlemleri, platformun güvenliği...     Fonksiyonel  ChatGPT\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40 entries, 0 to 39\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Gereksinimler    40 non-null     object\n",
      " 1   Gereksinim Tipi  40 non-null     object\n",
      " 2   Yazar            40 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.1+ KB\n",
      "None\n",
      "Modelin doğruluk değeri: 0.375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Veri setini yükleme\n",
    "data_path = r'C:\\Users\\Gizem\\Desktop\\Veri_Seti_ChatGPT_İnsan.xlsx'\n",
    "data = pd.read_excel(data_path)\n",
    "\n",
    "# Veri setinin ilk beş satırını göster\n",
    "print(data.head())\n",
    "\n",
    "# Veri setinin sütun başlıklarını ve veri türlerini göster\n",
    "print(data.info())\n",
    "\n",
    "# Bağımlı ve bağımsız değişkenleri ayırma\n",
    "X = data['Gereksinimler']  # Bağımsız değişken\n",
    "y = data['Yazar']  # Bağımlı değişken\n",
    "\n",
    "# 'Gereksinim Tipi' sütununu da X'e ekleme\n",
    "X = data['Gereksinimler'] + ' ' + data['Gereksinim Tipi']\n",
    "\n",
    "# Metin verisini sayısal hale getirme (TF-IDF)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# 'Yazar' sütununu sayısal değerlere dönüştürme\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Eğitim ve test veri setlerini ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# SVM modelini tanımlama ve eğitme\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Modelin performansını değerlendirme\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Modelin doğruluk değeri:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d1012be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Gizem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Gizem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Gereksinimler Gereksinim Tipi    Yazar\n",
      "0  Kullanıcıların profil bilgilerini güncelleyebi...     Fonksiyonel  ChatGPT\n",
      "1  Profil oluşturma sırasında, evcil hayvanın tem...     Fonksiyonel  ChatGPT\n",
      "2  Kullanıcılar, evcil hayvanlarının sağlık geçmi...     Fonksiyonel  ChatGPT\n",
      "3  Randevu talepleri, platform üzerinden veterine...     Fonksiyonel  ChatGPT\n",
      "4  Veri güvenliği önlemleri, platformun güvenliği...     Fonksiyonel  ChatGPT\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40 entries, 0 to 39\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Gereksinimler    40 non-null     object\n",
      " 1   Gereksinim Tipi  40 non-null     object\n",
      " 2   Yazar            40 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.1+ KB\n",
      "None\n",
      "TF-IDF - Lojistik Regresyon ile Performans:\n",
      "Precision: 0.28\n",
      "Recall: 0.25\n",
      "F1-Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[1 4]\n",
      " [2 1]]\n",
      "\n",
      "TF-IDF - Karar Ağacı ile Performans:\n",
      "Precision: 0.28\n",
      "Recall: 0.25\n",
      "F1-Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[1 4]\n",
      " [2 1]]\n",
      "\n",
      "TF-IDF - Rastgele Orman ile Performans:\n",
      "Precision: 0.28\n",
      "Recall: 0.25\n",
      "F1-Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[1 4]\n",
      " [2 1]]\n",
      "\n",
      "TF-IDF - SVM ile Performans:\n",
      "Precision: 0.28\n",
      "Recall: 0.25\n",
      "F1-Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[1 4]\n",
      " [2 1]]\n",
      "\n",
      "TF-IDF - KNN ile Performans:\n",
      "Precision: 0.28\n",
      "Recall: 0.25\n",
      "F1-Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[1 4]\n",
      " [2 1]]\n",
      "\n",
      "CountVector - Lojistik Regresyon ile Performans:\n",
      "Precision: 0.28\n",
      "Recall: 0.25\n",
      "F1-Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[1 4]\n",
      " [2 1]]\n",
      "\n",
      "CountVector - Karar Ağacı ile Performans:\n",
      "Precision: 0.28\n",
      "Recall: 0.25\n",
      "F1-Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[1 4]\n",
      " [2 1]]\n",
      "\n",
      "CountVector - Rastgele Orman ile Performans:\n",
      "Precision: 0.28\n",
      "Recall: 0.25\n",
      "F1-Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[1 4]\n",
      " [2 1]]\n",
      "\n",
      "CountVector - SVM ile Performans:\n",
      "Precision: 0.28\n",
      "Recall: 0.25\n",
      "F1-Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[1 4]\n",
      " [2 1]]\n",
      "\n",
      "CountVector - KNN ile Performans:\n",
      "Precision: 0.14\n",
      "Recall: 0.38\n",
      "F1-Score: 0.20\n",
      "Confusion Matrix:\n",
      "[[0 5]\n",
      " [0 3]]\n",
      "\n",
      "Word2Vec - Lojistik Regresyon ile Performans:\n",
      "Precision: 0.14\n",
      "Recall: 0.38\n",
      "F1-Score: 0.20\n",
      "Confusion Matrix:\n",
      "[[0 5]\n",
      " [0 3]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec - Karar Ağacı ile Performans:\n",
      "Precision: 0.28\n",
      "Recall: 0.25\n",
      "F1-Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[1 4]\n",
      " [2 1]]\n",
      "\n",
      "Word2Vec - Rastgele Orman ile Performans:\n",
      "Precision: 0.28\n",
      "Recall: 0.25\n",
      "F1-Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[1 4]\n",
      " [2 1]]\n",
      "\n",
      "Word2Vec - SVM ile Performans:\n",
      "Precision: 0.14\n",
      "Recall: 0.38\n",
      "F1-Score: 0.20\n",
      "Confusion Matrix:\n",
      "[[0 5]\n",
      " [0 3]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec - KNN ile Performans:\n",
      "Precision: 0.28\n",
      "Recall: 0.25\n",
      "F1-Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[1 4]\n",
      " [2 1]]\n",
      "\n",
      "Doc2Vec - Lojistik Regresyon ile Performans:\n",
      "Precision: 0.14\n",
      "Recall: 0.38\n",
      "F1-Score: 0.20\n",
      "Confusion Matrix:\n",
      "[[0 5]\n",
      " [0 3]]\n",
      "\n",
      "Doc2Vec - Karar Ağacı ile Performans:\n",
      "Precision: 0.57\n",
      "Recall: 0.50\n",
      "F1-Score: 0.50\n",
      "Confusion Matrix:\n",
      "[[2 3]\n",
      " [1 2]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec - Rastgele Orman ile Performans:\n",
      "Precision: 0.79\n",
      "Recall: 0.50\n",
      "F1-Score: 0.43\n",
      "Confusion Matrix:\n",
      "[[1 4]\n",
      " [0 3]]\n",
      "\n",
      "Doc2Vec - SVM ile Performans:\n",
      "Precision: 0.14\n",
      "Recall: 0.38\n",
      "F1-Score: 0.20\n",
      "Confusion Matrix:\n",
      "[[0 5]\n",
      " [0 3]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec - KNN ile Performans:\n",
      "Precision: 0.85\n",
      "Recall: 0.75\n",
      "F1-Score: 0.75\n",
      "Confusion Matrix:\n",
      "[[3 2]\n",
      " [0 3]]\n",
      "\n",
      "One-Hot - Lojistik Regresyon ile Performans:\n",
      "Precision: 0.28\n",
      "Recall: 0.25\n",
      "F1-Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[1 4]\n",
      " [2 1]]\n",
      "\n",
      "One-Hot - Karar Ağacı ile Performans:\n",
      "Precision: 0.28\n",
      "Recall: 0.25\n",
      "F1-Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[1 4]\n",
      " [2 1]]\n",
      "\n",
      "One-Hot - Rastgele Orman ile Performans:\n",
      "Precision: 0.28\n",
      "Recall: 0.25\n",
      "F1-Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[1 4]\n",
      " [2 1]]\n",
      "\n",
      "One-Hot - SVM ile Performans:\n",
      "Precision: 0.28\n",
      "Recall: 0.25\n",
      "F1-Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[1 4]\n",
      " [2 1]]\n",
      "\n",
      "One-Hot - KNN ile Performans:\n",
      "Precision: 0.14\n",
      "Recall: 0.38\n",
      "F1-Score: 0.20\n",
      "Confusion Matrix:\n",
      "[[0 5]\n",
      " [0 3]]\n",
      "\n",
      "Tüm Sonuçlar:\n",
      "{'TF-IDF': {'Lojistik Regresyon': {'Precision': 0.2833333333333333, 'Recall': 0.25, 'F1-Score': 0.25, 'Confusion Matrix': array([[1, 4],\n",
      "       [2, 1]], dtype=int64)}, 'Karar Ağacı': {'Precision': 0.2833333333333333, 'Recall': 0.25, 'F1-Score': 0.25, 'Confusion Matrix': array([[1, 4],\n",
      "       [2, 1]], dtype=int64)}, 'Rastgele Orman': {'Precision': 0.2833333333333333, 'Recall': 0.25, 'F1-Score': 0.25, 'Confusion Matrix': array([[1, 4],\n",
      "       [2, 1]], dtype=int64)}, 'SVM': {'Precision': 0.2833333333333333, 'Recall': 0.25, 'F1-Score': 0.25, 'Confusion Matrix': array([[1, 4],\n",
      "       [2, 1]], dtype=int64)}, 'KNN': {'Precision': 0.2833333333333333, 'Recall': 0.25, 'F1-Score': 0.25, 'Confusion Matrix': array([[1, 4],\n",
      "       [2, 1]], dtype=int64)}}, 'CountVector': {'Lojistik Regresyon': {'Precision': 0.2833333333333333, 'Recall': 0.25, 'F1-Score': 0.25, 'Confusion Matrix': array([[1, 4],\n",
      "       [2, 1]], dtype=int64)}, 'Karar Ağacı': {'Precision': 0.2833333333333333, 'Recall': 0.25, 'F1-Score': 0.25, 'Confusion Matrix': array([[1, 4],\n",
      "       [2, 1]], dtype=int64)}, 'Rastgele Orman': {'Precision': 0.2833333333333333, 'Recall': 0.25, 'F1-Score': 0.25, 'Confusion Matrix': array([[1, 4],\n",
      "       [2, 1]], dtype=int64)}, 'SVM': {'Precision': 0.2833333333333333, 'Recall': 0.25, 'F1-Score': 0.25, 'Confusion Matrix': array([[1, 4],\n",
      "       [2, 1]], dtype=int64)}, 'KNN': {'Precision': 0.140625, 'Recall': 0.375, 'F1-Score': 0.20454545454545453, 'Confusion Matrix': array([[0, 5],\n",
      "       [0, 3]], dtype=int64)}}, 'Word2Vec': {'Lojistik Regresyon': {'Precision': 0.140625, 'Recall': 0.375, 'F1-Score': 0.20454545454545453, 'Confusion Matrix': array([[0, 5],\n",
      "       [0, 3]], dtype=int64)}, 'Karar Ağacı': {'Precision': 0.2833333333333333, 'Recall': 0.25, 'F1-Score': 0.25, 'Confusion Matrix': array([[1, 4],\n",
      "       [2, 1]], dtype=int64)}, 'Rastgele Orman': {'Precision': 0.2833333333333333, 'Recall': 0.25, 'F1-Score': 0.25, 'Confusion Matrix': array([[1, 4],\n",
      "       [2, 1]], dtype=int64)}, 'SVM': {'Precision': 0.140625, 'Recall': 0.375, 'F1-Score': 0.20454545454545453, 'Confusion Matrix': array([[0, 5],\n",
      "       [0, 3]], dtype=int64)}, 'KNN': {'Precision': 0.2833333333333333, 'Recall': 0.25, 'F1-Score': 0.25, 'Confusion Matrix': array([[1, 4],\n",
      "       [2, 1]], dtype=int64)}}, 'Doc2Vec': {'Lojistik Regresyon': {'Precision': 0.140625, 'Recall': 0.375, 'F1-Score': 0.20454545454545453, 'Confusion Matrix': array([[0, 5],\n",
      "       [0, 3]], dtype=int64)}, 'Karar Ağacı': {'Precision': 0.5666666666666667, 'Recall': 0.5, 'F1-Score': 0.5, 'Confusion Matrix': array([[2, 3],\n",
      "       [1, 2]], dtype=int64)}, 'Rastgele Orman': {'Precision': 0.7857142857142857, 'Recall': 0.5, 'F1-Score': 0.43333333333333335, 'Confusion Matrix': array([[1, 4],\n",
      "       [0, 3]], dtype=int64)}, 'SVM': {'Precision': 0.140625, 'Recall': 0.375, 'F1-Score': 0.20454545454545453, 'Confusion Matrix': array([[0, 5],\n",
      "       [0, 3]], dtype=int64)}, 'KNN': {'Precision': 0.85, 'Recall': 0.75, 'F1-Score': 0.7499999999999999, 'Confusion Matrix': array([[3, 2],\n",
      "       [0, 3]], dtype=int64)}}, 'One-Hot': {'Lojistik Regresyon': {'Precision': 0.2833333333333333, 'Recall': 0.25, 'F1-Score': 0.25, 'Confusion Matrix': array([[1, 4],\n",
      "       [2, 1]], dtype=int64)}, 'Karar Ağacı': {'Precision': 0.2833333333333333, 'Recall': 0.25, 'F1-Score': 0.25, 'Confusion Matrix': array([[1, 4],\n",
      "       [2, 1]], dtype=int64)}, 'Rastgele Orman': {'Precision': 0.2833333333333333, 'Recall': 0.25, 'F1-Score': 0.25, 'Confusion Matrix': array([[1, 4],\n",
      "       [2, 1]], dtype=int64)}, 'SVM': {'Precision': 0.2833333333333333, 'Recall': 0.25, 'F1-Score': 0.25, 'Confusion Matrix': array([[1, 4],\n",
      "       [2, 1]], dtype=int64)}, 'KNN': {'Precision': 0.140625, 'Recall': 0.375, 'F1-Score': 0.20454545454545453, 'Confusion Matrix': array([[0, 5],\n",
      "       [0, 3]], dtype=int64)}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Gizem\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# NLTK kütüphanesinin durak kelimeler ve WordNet lemmatizer'ını indir\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Veri setini yükleme\n",
    "data_path = r'C:\\Users\\Gizem\\Desktop\\Veri_Seti_ChatGPT_İnsan.xlsx'\n",
    "data = pd.read_excel(data_path)\n",
    "\n",
    "# Veri setinin ilk beş satırını göster\n",
    "print(data.head())\n",
    "\n",
    "# Veri setinin sütun başlıklarını ve veri türlerini göster\n",
    "print(data.info())\n",
    "\n",
    "# Durak kelimeler listesi\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Lemmatizer nesnesi\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Küçük harfe çevirme\n",
    "    text = text.lower()\n",
    "    # Noktalama işaretlerini ve sayıları kaldır\n",
    "    text = re.sub(r'[\\d\\W]+', ' ', text)\n",
    "    # Tokenize etme ve durak kelimeleri kaldırma\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Kelimeleri kökten ayırma\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # Temizlenmiş metni geri döndür\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Metin sütununu önişle\n",
    "data['Processed_Text'] = data['Gereksinimler'].apply(preprocess_text)\n",
    "\n",
    "# Bağımlı ve bağımsız değişkenleri ayırma\n",
    "X = data['Gereksinim Tipi']\n",
    "y = data['Yazar']\n",
    "\n",
    "# TF-IDF öznitelik çıkarımı\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Count Vectorizer öznitelik çıkarımı\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_count = count_vectorizer.fit_transform(X)\n",
    "\n",
    "# Word2Vec öznitelik çıkarımı\n",
    "sentences = [text.split() for text in X]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "word2vec_vectors = np.array([np.mean([word2vec_model.wv[word] for word in words if word in word2vec_model.wv] or [np.zeros(100)], axis=0) for words in sentences])\n",
    "\n",
    "# Doc2Vec öznitelik çıkarımı\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(sentences)]\n",
    "doc2vec_model = Doc2Vec(documents, vector_size=100, window=5, min_count=1, epochs=20)\n",
    "doc2vec_vectors = np.array([doc2vec_model.dv[i] for i in range(len(documents))])\n",
    "\n",
    "# One-Hot Encoding\n",
    "onehot_vectorizer = CountVectorizer(binary=True)\n",
    "X_onehot = onehot_vectorizer.fit_transform(X)\n",
    "\n",
    "# 'Yazar' sütununu sayısal değerlere dönüştürme\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Öznitelik setlerini bir sözlükte toplama\n",
    "feature_sets = {\n",
    "    \"TF-IDF\": X_tfidf,\n",
    "    \"CountVector\": X_count,\n",
    "    \"Word2Vec\": word2vec_vectors,\n",
    "    \"Doc2Vec\": doc2vec_vectors,\n",
    "    \"One-Hot\": X_onehot\n",
    "}\n",
    "\n",
    "# Modelleri tanımlama\n",
    "models = {\n",
    "    \"Lojistik Regresyon\": LogisticRegression(max_iter=1000),\n",
    "    \"Karar Ağacı\": DecisionTreeClassifier(),\n",
    "    \"Rastgele Orman\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Her öznitelik seti ve model için eğitim, test ve performans değerlendirmesi yapma\n",
    "results = {}\n",
    "for feature_name, features in feature_sets.items():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, y_encoded, test_size=0.2, random_state=42)\n",
    "    results[feature_name] = {}\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        results[feature_name][model_name] = {\n",
    "            \"Precision\": report['weighted avg']['precision'],\n",
    "            \"Recall\": report['weighted avg']['recall'],\n",
    "            \"F1-Score\": report['weighted avg']['f1-score'],\n",
    "            \"Confusion Matrix\": cm\n",
    "        }\n",
    "        print(f\"{feature_name} - {model_name} ile Performans:\")\n",
    "        print(f\"Precision: {report['weighted avg']['precision']:.2f}\")\n",
    "        print(f\"Recall: {report['weighted avg']['recall']:.2f}\")\n",
    "        print(f\"F1-Score: {report['weighted avg']['f1-score']:.2f}\")\n",
    "        print(f\"Confusion Matrix:\\n{cm}\\n\")\n",
    "\n",
    "# Sonuçları topluca yazdırma (isteğe bağlı)\n",
    "print(\"Tüm Sonuçlar:\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b37a1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
